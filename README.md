# WINCASA - Intelligentes Datenbank-Abfrage-System

[![GitHub Repository](https://img.shields.io/badge/GitHub-fhalamzie%2Flangchain__project-blue?logo=github)](https://github.com/fhalamzie/langchain_project)
[![Phoenix Monitoring](https://img.shields.io/badge/Phoenix-AI%20Observability-green?logo=phoenix-framework)](http://localhost:6006)
[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-success)]()

## Projekt√ºbersicht

WINCASA ist ein produktionsbereites System zur nat√ºrlichsprachigen Abfrage von Firebird-Datenbanken. Das System nutzt moderne LLM-Technologie (GPT-4) in Kombination mit direkter Datenbankanbindung und erweiterten RAG-Verfahren (Retrieval Augmented Generation), um komplexe Datenbankabfragen in nat√ºrlicher Sprache zu erm√∂glichen.

**Status: ‚úÖ Produktionsbereit** - Alle Kernfunktionen implementiert und getestet.

## üìÇ GitHub Repository

**Repository**: https://github.com/fhalamzie/langchain_project

```bash
# Code klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project
```

## üöÄ Quick Start

### Produktions-Setup

#### Option 1: Von GitHub klonen
```bash
# 1. Repository klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# 2. Umgebung vorbereiten
python3 -m venv .venv
source .venv/bin/activate

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. API-Schl√ºssel konfigurieren
mkdir -p /home/envs
echo "OPENAI_API_KEY=your_api_key_here" > /home/envs/openai.env

# 5. System starten
./start_enhanced_qa_direct.sh
```

#### Option 2: Docker Deployment
```bash
# Repository klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# Mit Docker starten
docker-compose up -d
```

**URL**: `http://localhost:8501`

## üèóÔ∏è Systemarchitektur

### Hauptkomponenten
- **[`firebird_sql_agent_direct.py`](firebird_sql_agent_direct.py)** - SQL-Agent mit direkter FDB-Integration
- **[`fdb_direct_interface.py`](fdb_direct_interface.py)** - Direkte Firebird-Datenbankschnittstelle
- **[`enhanced_qa_ui.py`](enhanced_qa_ui.py)** - Streamlit Web-Interface
- **[`enhanced_retrievers.py`](enhanced_retrievers.py)** - Multi-Stage RAG-System
- **[`db_knowledge_compiler.py`](db_knowledge_compiler.py)** - Database Knowledge System
- **[`generate_yaml_ui.py`](generate_yaml_ui.py)** - Skript zur Generierung der YAML-basierten Wissensbasis und der zugeh√∂rigen UI-Komponenten (verantwortlich f√ºr aktuellen Output-Stil der YAMLs und Schema-Dokumentation).

## üß™ Testing

### Haupttests
```bash
python test_enhanced_qa_ui_integration.py
python test_fdb_direct_interface.py
python test_firebird_sql_agent.py
python automated_retrieval_test.py
```

## üéÆ Produktiver Betrieb

### Production UI (Empfohlen)
```bash
# Clean Production Interface
source .venv/bin/activate
./start_clean_qa.sh
# URL: http://localhost:8501
```

### Alternative Startmethoden
```bash
streamlit run enhanced_qa_ui.py
python run_llm_query.py
```

## üí¨ Beispielabfragen

- *"Wer wohnt in der Marienstra√üe 26, 45307 Essen?"*
- *"Wie viele Wohnungen gibt es insgesamt?"*
- *"Zeige mir Bewohner mit ihren Adressdaten"*
- *"Welche Eigent√ºmer gibt es in K√∂ln?"*

## üìä Performance

- **Database**: 151 Tabellen, 517 Wohnungen, 698 Bewohner
- **Retrieval Modi**: Enhanced (22.5s), None (20.8s), FAISS (34.6s)
- **Erfolgsrate**: 63.6% √ºber alle Modi

## üîß Systemanforderungen

- **Python 3.8+**
- **Firebird-Datenbank** (WINCASA2022.FDB)
- **OpenAI API-Schl√ºssel**
- **Dependencies**: langchain, streamlit, faiss-cpu, fdb, PyYAML
- **Monitoring**: arize-phoenix (f√ºr AI Observability)

## üìÅ Datenorganisation

- **`/output/yamls/`**: 248 YAML Business-Context-Dateien
- **`/output/compiled_knowledge_base.json`**: Kompilierte Wissensbasis
- **`/home/envs/`**: API-Konfigurationsdateien

## üìä AI Observability (‚úÖ Implementiert)

### Phoenix Integration
```bash
pip install arize-phoenix
```

**Features:**
- ‚úÖ **LLM Tracing**: Vollst√§ndige √úberwachung aller OpenAI API-Aufrufe
- ‚úÖ **RAG Evaluation**: Performance-Tracking f√ºr Enhanced/FAISS/None Modi
- ‚úÖ **Query Analytics**: End-to-End Query-Execution-Metriken
- ‚úÖ **Cost Tracking**: Automatische Kostenberechnung pro Query
- ‚úÖ **Phoenix Dashboard**: Interaktives Dashboard unter http://localhost:6006

**Integration Points:**
- `phoenix_monitoring.py`: Zentrale Monitoring-Infrastruktur
- `firebird_sql_agent_direct.py`: LLM & SQL Execution Tracking
- `enhanced_retrievers.py`: RAG Performance Monitoring
- `enhanced_qa_ui.py`: Dashboard-Links und Live-Metriken
- `automated_retrieval_test.py`: Test Framework mit Metrics Export

## üí° Kontextstrategie und Retrieval

Um die Genauigkeit und Effizienz der Datenbankabfragen weiter zu verbessern, wird eine hybride Kontextstrategie verfolgt. Diese kombiniert einen statischen, globalen Basiskontext mit dynamischem, anfragebasiertem Retrieval.

### Hybride Kontextstrategie

1.  **Globaler Basiskontext:**
    *   **Beschreibung:** Ein sorgf√§ltig ausgew√§hlter Satz an Kerninformationen √ºber das Datenbankschema, wichtige Entit√§ten, Schl√ºsselbeziehungen und grundlegende Gesch√§ftsregeln.
    *   **Zweck:** Stellt sicher, dass das LLM bei jeder Anfrage √ºber ein fundamentales Verst√§ndnis der Datenbank verf√ºgt.
    *   **Quelle:** Extrakte aus `docs/index.md`, `output/schema/index.md`, `output/schema/db_overview.md` und anderen relevanten Dokumenten.

2.  **Dynamisches Embedding-basiertes Retrieval:**
    *   **Beschreibung:** Nutzt die bestehenden RAG-Mechanismen (z.B. "Enhanced Mode", FAISS), um detaillierte oder spezifische Informationen dynamisch basierend auf der Nutzeranfrage abzurufen.
    *   **Zweck:** Erm√∂glicht den Zugriff auf eine umfangreiche Wissensbasis (`output/compiled_knowledge_base.json`, YAML-Detaildateien), ohne das Kontextfenster des LLMs bei jeder Anfrage zu √ºberlasten.
    *   **Funktionsweise:** Erg√§nzt den globalen Basiskontext mit spezifischen Details, die f√ºr die aktuelle Anfrage relevant sind.

Diese Strategie zielt darauf ab, dem LLM stets den relevantesten Kontext zur Verf√ºgung zu stellen, die Qualit√§t der generierten SQL-Abfragen zu erh√∂hen und die Fehleranf√§lligkeit (z.B. Timeouts) zu reduzieren. Details zur Implementierung finden sich im [`implementation_plan.md`](implementation_plan.md).
### Modell-Evaluierung und Embedding-Optimierung

Zur weiteren Steigerung der Systemleistung wurden folgende Ma√ünahmen umgesetzt:

*   **LLM-Modellvergleich:** Verschiedene LLMs (z.B. GPT-4-Varianten, Claude-Modelle, Gemini-Modelle) wurden systematisch evaluiert, um das optimale Modell f√ºr die spezifischen Anforderungen der WINCASA-Datenbankabfragen zu identifizieren. Die Ergebnisse dieser Vergleiche flie√üen kontinuierlich in die Modellauswahl ein. Das Skript [`automated_retrieval_test.py`](automated_retrieval_test.py) dient hierbei als zentrale Testumgebung.
*   **Upgrade auf Large Embedding Modell:** Um die Qualit√§t des semantischen Verst√§ndnisses und damit die Relevanz der abgerufenen Dokumente im RAG-Prozess zu verbessern, wurde auf ein leistungsf√§higeres, gr√∂√üeres Embedding-Modell (z.B. `text-embedding-3-large` von OpenAI) umgestellt. Dies f√ºhrt zu pr√§ziseren Kontextinformationen f√ºr das LLM.

Diese Optimierungen sind Teil der kontinuierlichen Bem√ºhungen, die Effektivit√§t und Genauigkeit des WINCASA-Systems zu maximieren.
## ÔøΩ Backup & Versionskontrolle

### GitHub Integration
Das komplette Projekt ist auf GitHub gesichert:
- **Repository**: https://github.com/fhalamzie/langchain_project
- **Backup-Status**: ‚úÖ Alle Commits synchronisiert
- **Versionskontrolle**: Git-Historie vollst√§ndig verf√ºgbar

### Code-Backup
```bash
# √Ñnderungen sichern
git add .
git commit -m "Beschreibung der √Ñnderungen"
git push origin main
```

### Projekt wiederherstellen
```bash
# Von GitHub klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# Setup durchf√ºhren
pip install -r requirements.txt
./start_enhanced_qa_direct.sh
```

## üß™ Entwicklungsstandards

### Testing
- 100% Coverage f√ºr neue Features
- pytest Framework
- Mock externe Dependencies

### Git Workflow
- Commit pro Major Change
- Conventional Commits Format
- Push zu Remote Repository
- Dokumentation bei Code-√Ñnderungen

---

**Status: ‚úÖ PRODUCTION-READY**

Details: [`CLAUDE.md`](CLAUDE.md) | [`implementation_status.md`](implementation_status.md)