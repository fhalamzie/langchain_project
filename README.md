# WINCASA - Datenbank-Dokumentationsgenerator & Abfrage-Tool

## Projekt√ºbersicht

Dieses Projekt ist ein umfassendes Tool zur automatisierten Dokumentation und intelligenten Abfrage einer Firebird-Datenbank (WINCASA2022.FDB). Es kombiniert traditionelle Datenbanktechnologien mit modernen LLM-basierten (Large Language Model) Methoden, um eine intuitive, nat√ºrlichsprachige Interaktion mit komplexen Datenbankstrukturen zu erm√∂glichen.
Das System integriert zwei parallele RAG-Ans√§tze (FAISS und Neo4j) f√ºr erweiterte Kontextualisierung und h√∂here Abfragegenauigkeit. Der detaillierte Implementierungsplan ist unter [`plan.md`](plan.md) und der aktuelle Fortschritt unter [`implementation_status.md`](implementation_status.md) zu finden.

## Hauptfunktionen

Das System bietet folgende Kernfunktionalit√§ten:

1. **Automatisierte Dokumentation der Datenbankstruktur**
   - Extraktion von Tabellen, Spalten, Beziehungen und Gesch√§ftsregeln
   - Generierung von Markdown- und YAML-Dokumentation
   - Optimierung bestehender Dokumentation mit Kontextinformationen

2. **Nat√ºrlichsprachige Datenbankabfragen**
   - Umwandlung nat√ºrlicher Sprache in SQL-Abfragen
   - Intelligente Kontextauswahl relevanter Tabellen
   - Pr√§sentation der Ergebnisse in benutzerfreundlichem Format

3. **Streamlit-basierte Benutzeroberfl√§che**
   - Interaktive UI f√ºr alle Systemfunktionen
   - Unterschiedliche Tabs f√ºr verschiedene Anwendungsf√§lle
   - Feedback-Mechanismen zur kontinuierlichen Verbesserung

4. **Sicherheitsfeatures**
   - Validierung von SQL-Abfragen
   - Beschr√§nkung auf SELECT-Operationen
   - Timeout- und Ressourcenbegrenzungen

5. **Caching und Protokollierung**
   - Caching von Abfrageergebnissen f√ºr bessere Performance
   - Ausf√ºhrliche Protokollierung f√ºr Audit und Optimierung
   - Speicherung von Benutzer-Feedback

## Systemarchitektur

Das System ist modular aufgebaut und besteht aus folgenden Hauptkomponenten:

### 1. Datenbankzugriff

- **query_router.py**: Zentrale Komponente f√ºr den Datenbankzugriff
  - Verbindungsaufbau zur Firebird-Datenbank
  - Dynamische Suche nach der Firebird-Client-Library
  - Fehlerbehandlung und Logging

- **db_executor.py**: Sichere Ausf√ºhrung von SQL-Abfragen
  - Validierung von SQL-Anfragen (nur SELECT erlaubt)
  - Caching-Mechanismus f√ºr Abfrageergebnisse
  - Timeout-Handling und Ressourcenbegrenzung
  - Konvertierung von Kodierungen (WIN1252 zu UTF-8)

### 2. LLM-Integration

- **llm_interface.py**: Schnittstelle zu OpenAI-API
  - Initialisierung von ChatOpenAI mit GPT-4
  - Generierung von SQL aus nat√ºrlichsprachigen Anfragen
  - Verarbeitung von Schema-Kontext

- **qa_enhancer.py**: Erweiterte Q&A-Funktionalit√§t
  - Semantische Suche nach relevanten Tabellen
  - Kontextoptimierung f√ºr LLM-Anfragen
  - Nat√ºrlichsprachige Aufbereitung von Abfrageergebnissen
  - Feedback-Speicherung und kontinuierliche Verbesserung

### 3. Benutzeroberfl√§che

- **streamlit_integration.py**: Hauptanwendung
  - Integration aller Komponenten in einer einheitlichen UI
  - Tab-basierte Navigation f√ºr verschiedene Funktionalit√§ten
  - Dynamisches Laden von Modulen

- **enhanced_qa_ui.py**: UI f√ºr nat√ºrlichsprachige Abfragen
  - Eingabeformular f√ºr Benutzeranfragen
  - Anzeige von SQL, Tabellen und Ergebnissen
  - Feedback-Mechanismen (Bewertung von Antworten)

### 4. Unterst√ºtzende Komponenten

- **query_memory.py**: Speicherung von Abfragehistorie
  - Protokollierung erfolgreicher und fehlgeschlagener Abfragen
  - Speicherung manueller Korrekturen

- **query_logger.py**: Detaillierte Protokollierung
  - Speicherung von Anfragen, SQL, Ergebnissen
  - Zeitstempel und Erfolgsmetriken

### 5. Datenstrukturen

Das Projekt organisiert generierte Daten in strukturierten Verzeichnissen:

- **/output/schema/**: Enth√§lt detaillierte Dokumentation zur Datenbankstruktur:
    - `index.md`: Ein Gesamtinhaltsverzeichnis aller Tabellen und Prozeduren.
    - `relation_report.md`: Ein Bericht √ºber die Beziehungen zwischen den Tabellen, inklusive einer Liste der am st√§rksten verbundenen Tabellen.
    - `table_diagrams.md`: Links zu einzelnen Diagrammen, die die direkten Beziehungen jeder Tabelle visualisieren.
    - `table_clusters.md`: Eine Analyse, die Tabellen basierend auf ihren Beziehungen in Cluster gruppiert. Dies hilft, funktionale Module innerhalb der Datenbank zu identifizieren.
    - Individuelle Markdown-Dateien f√ºr jede Tabelle (z.B., `KONTEN.md`, `OBJEKTE.md`), die Spalten, Datentypen, Beschreibungen und Beziehungen detailliert beschreiben.
- **/output/yamls/**: YAML-Repr√§sentationen von Datenbankobjekten (Tabellen und Prozeduren), die f√ºr die programmatische Verarbeitung des Schemas genutzt werden.
- **/output/logs/**: Protokolldateien und Statusberichte, z.B. `llm_prompts.log`.
- **/output/memory/**: Verlauf von Benutzeranfragen und deren Ergebnisse.
- **/output/feedback/**: Gesammeltes Benutzerfeedback zur Systemperformance.
- **/output/cache/**: Zwischengespeicherte Abfrageergebnisse zur Performanceoptimierung.

## Ablauf einer Benutzeranfrage

Der typische Ablauf einer nat√ºrlichsprachigen Datenbankabfrage wird derzeit √ºberarbeitet, um einen Langchain SQL Agent zu nutzen. Der geplante Ablauf ist in [`plan.md`](plan.md) dokumentiert und beinhaltet die Nutzung von RAG (Retrieval Augmented Generation) zur Anreicherung des Kontexts f√ºr den Agenten. Der bisherige Ablauf umfasste:

1.  Eingabe der Benutzeranfrage √ºber die Streamlit-UI
2.  Identifikation relevanter Tabellen durch semantische √Ñhnlichkeitssuche (TF-IDF)
3.  Erstellung eines Tabellenkontexts
4.  Generierung einer SQL-Abfrage durch das LLM
5.  Validierung und Ausf√ºhrung der SQL-Abfrage
6.  Verarbeitung und Formatierung der Ergebnisse
7.  Generierung einer nat√ºrlichsprachigen Antwort durch das LLM
8.  Pr√§sentation der Ergebnisse und Antwort in der UI
9.  Protokollierung und optionales Feedback

## Installation und Einrichtung

### Voraussetzungen

- Python 3.8+
- Firebird-Datenbank (WINCASA2022.FDB)
- OpenAI API-Schl√ºssel

### Installation

1. Repository klonen
2. Virtuelle Umgebung erstellen und aktivieren:
   ```
   python3 -m venv .venv
   source .venv/bin/activate  # Unter Linux/macOS
   # oder
   .venv\Scripts\activate     # Unter Windows
   ```
3. Abh√§ngigkeiten installieren:
   ```
   pip install langchain langchain-community langchain-openai streamlit pandas numpy scikit-learn fdb faiss-cpu neo4j neo4j-graphrag tiktoken PyYAML python-dotenv
   ```
4. OpenAI API-Schl√ºssel in `/home/envs/openai.env` hinterlegen:
   ```
   OPENAI_API_KEY=your_api_key_here
   ```
5. Stellen Sie sicher, dass die Firebird-Client-Bibliothek verf√ºgbar ist. Sie kann unter `./lib/libfbclient.so` platziert werden.

### Verzeichnisstruktur vorbereiten

```
mkdir -p output/schema output/yamls output/logs output/memory output/feedback output/cache fb_temp
```

### Wichtiger Hinweis zur Ausf√ºhrung

Alle Skripte m√ºssen innerhalb der aktivierten virtuellen Umgebung ausgef√ºhrt werden. Vor der Ausf√ºhrung immer sicherstellen, dass die Umgebung aktiviert ist:

```
source .venv/bin/activate  # Unter Linux/macOS
# oder
.venv\Scripts\activate     # Unter Windows
```

## Ausf√ºhrung

Das System bietet verschiedene Einstiegspunkte:

### Streamlit-Anwendung starten:

```
# Virtuelle Umgebung aktivieren
source .venv/bin/activate

# Anwendung starten
streamlit run streamlit_integration.py
```

### Kommandozeilen-Query ausf√ºhren:

```
# Virtuelle Umgebung aktivieren
source .venv/bin/activate

# Query ausf√ºhren
python run_llm_query.py
```

### Erweiterte Q&A-Benutzeroberfl√§che (Direkte FDB-Schnittstelle):

```
# Virtuelle Umgebung aktivieren
source .venv/bin/activate

# UI mit direkter FDB-Schnittstelle starten
streamlit run enhanced_qa_ui.py

# Oder mit dem neuen Startskript:
./start_enhanced_qa_direct.sh

### Neo4j-Integration

F√ºr die Nutzung des Neo4j RAG-Pfads:
1. Neo4j-Instanz starten:
```bash
docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j
```
2. Dokumentation importieren:
```python
from neo4j_importer import Neo4jImporter

importer = Neo4jImporter("bolt://localhost:7687", "neo4j", "password", "doc_index")
importer.create_index()
importer.import_documents(docs)  # docs aus _load_and_parse_documentation
```
```

**üéâ Neue Features der direkten FDB-Schnittstelle:**
- Umgeht SQLAlchemy-Sperrprobleme (SQLCODE -902)
- Automatisches Server/Embedded-Fallback
- Custom Langchain Tools f√ºr FDB-Operationen
- Verbesserte Fehlerbehandlung und Performance
- Detaillierte Agent-Schritte in der UI

### Lizenzinformationen pr√ºfen:

```
# Virtuelle Umgebung aktivieren
source .venv/bin/activate

# Lizenzpr√ºfung starten
python check_license.py
```

## Skripte und Hilfsprogramme

- **check_imports.py**: √úberpr√ºfung von Abh√§ngigkeiten
- **debug_env.py**: Debugging der Umgebungsvariablen
- **extract_from_firebird.py**: Extraktion von Daten aus der Firebird-DB
- **export_schema.py**: Export des Datenbankschemas
- **start_enhanced_qa.sh**: Startskript f√ºr die erweiterte Q&A-UI
- **start_streamlit.sh**: Startskript f√ºr die Streamlit-Anwendung

## Technischer Hintergrund

### LLM-Integration

Das System verwendet ChatOpenAI (GPT-4) f√ºr zwei Hauptzwecke:
1. **SQL-Generierung**: Umwandlung nat√ºrlichsprachiger Anfragen in SQL mit Ber√ºcksichtigung des Datenbankschemas
2. **Antwortgenerierung**: Aufbereitung von Abfrageergebnissen in nat√ºrlichsprachige, benutzerfreundliche Antworten

Die LLMs werden mit unterschiedlichen Parametern konfiguriert:
- F√ºr SQL-Generierung: Temperatur=0 (deterministische Antworten)
- F√ºr Antwortgenerierung: Temperatur=0.3 (leicht kreative Antworten)

### Semantische Suche

Zur Identifikation relevanter Tabellen wird TF-IDF (Term Frequency-Inverse Document Frequency) mit Cosine-Similarity verwendet:
1. Tabellennamen, Beschreibungen und Spalteninformationen werden in einen Vektor umgewandelt
2. Die Benutzeranfrage wird ebenfalls vektorisiert
3. Tabellen mit der h√∂chsten √Ñhnlichkeit zur Anfrage werden ausgew√§hlt

### Sicherheitsma√ünahmen

- **SQL-Validierung**: Regul√§re Ausdr√ºcke pr√ºfen auf gef√§hrliche Operationen
- **Timeout-Begrenzung**: Abfragen werden nach 30 Sekunden abgebrochen
- **Ergebnisbegrenzung**: Maximal 1000 Zeilen werden zur√ºckgegeben
- **Caching**: Ergebnisse werden zwischengespeichert, um wiederholte Abfragen zu beschleunigen

## Erweiterungsm√∂glichkeiten

Das System kann in folgenden Bereichen erweitert werden:

1. **Unterst√ºtzung weiterer Datenbanktypen** neben Firebird
2. **Implementierung von Benutzer-Authentifizierung und Berechtigungen**
3. **Erweiterte Analysen** der protokollierten Benutzerinteraktionen
4. **Integration mit Business Intelligence Tools**
5. **Optimierung der Kontextauswahl** f√ºr bessere SQL-Generierung
6. **Implementierung von Multi-Turn-Konversationen** f√ºr komplexere Abfragen

## Beispielabfragen

- "Welche Bewohner leben in der Marienstra√üe 26?"
- "Zeige mir alle Eigent√ºmer in Berlin"
- "Wie viele Wohnungen gibt es pro Geb√§ude?"
- "Welche Bankverbindungen haben wir f√ºr Eigent√ºmer?"

## Feedback und Verbesserung

Das System sammelt Benutzerfeedback zu generierten Antworten, um kontinuierlich zu lernen und sich zu verbessern. Benutzer k√∂nnen Antworten mit den Optionen "Sehr gut", "Gut", "Ungenau" oder "Falsch" bewerten.

## Zusammenfassung

Das WINCASA-Projekt demonstriert die erfolgreiche Integration von traditionellen Datenbanktechnologien mit modernen LLM-Ans√§tzen. Es erm√∂glicht Benutzern, komplexe Datenbankabfragen in nat√ºrlicher Sprache zu formulieren und verst√§ndliche Antworten zu erhalten, ohne SQL-Kenntnisse zu ben√∂tigen. Durch die Kombination von automatisierter Dokumentation, semantischer Suche und nat√ºrlichsprachiger Interaktion bietet es einen innovativen Ansatz f√ºr den Zugriff auf strukturierte Daten.

## Entwicklungsstand und Roadmap

Das Projekt durchl√§uft einen kontinuierlichen Verbesserungsprozess. Die aktuelle Roadmap und der detaillierte Implementierungsplan f√ºr den Langchain SQL Agent sind in [`plan.md`](plan.md) und der Fortschritt in [`implementation_status.md`](implementation_status.md) dokumentiert. Die urspr√ºngliche Roadmap umfasste:

### Urspr√ºngliche Herausforderungen

1. **Optimierung der Kontextauswahl**: Verbesserung der Relevanz von Tabellen f√ºr Anfragen
2. **SQL-Validierung und Sicherheit**: Implementierung robuster Sicherheitsmechanismen
3. **Ergebnisaufbereitung**: Strukturierung und Formatierung von Abfrageergebnissen
4. **Feedback-System**: Implementierung von Benutzerfeedback zur Systemverbesserung

### Geplante Verbesserungen

Die Implementierung erfolgt in vier Sprints:

#### Sprint 1: Grundlagen
- SQL-Ausf√ºhrungsmodul (bereits umgesetzt)
- Optimierte Kontextauswahl (bereits umgesetzt)

#### Sprint 2: Validierung und Ergebnisaufbereitung
- SQL-Validierung
- Ergebnis-Nachbearbeitung
- Nat√ºrlichsprachige Antwortgenerierung

#### Sprint 3: Feedback und UI
- Feedback-System
- Erweiterte UI-Komponenten

#### Sprint 4: Lernen und Integration
- Lernende Komponente
- Systemintegration

### Bekannte Risiken und Abh√§ngigkeiten

- **LLM-Tokengrenze**: Die Menge an Kontext, die an das LLM √ºbergeben werden kann, ist begrenzt
- **Sicherheitsbedenken**: Die Ausf√ºhrung generierter SQL-Abfragen erfordert strenge Validierung
- **Qualit√§t der Metadaten**: Die Effektivit√§t des Systems h√§ngt von der Qualit√§t der vorhandenen Metadaten ab

### Erfolgsmetriken

Die Leistung des Systems wird anhand folgender Metriken gemessen:
1. **Antwortgenauigkeit**: Prozentsatz korrekter Antworten
2. **SQL-Erfolgsrate**: Prozentsatz erfolgreich generierter und ausgef√ºhrter SQL-Abfragen
3. **Benutzer-Zufriedenheit**: Gemessen durch das Feedback-System
4. **Abfrageperformance**: Durchschnittliche Zeit von Anfrage bis Antwort
5. **Kontextrelevanz**: Prozentsatz relevanter Tabellen im ausgew√§hlten Kontext