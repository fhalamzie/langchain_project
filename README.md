# WINCASA - Intelligentes Datenbank-Abfrage-System

[![GitHub Repository](https://img.shields.io/badge/GitHub-fhalamzie%2Flangchain__project-blue?logo=github)](https://github.com/fhalamzie/langchain_project)
[![Phoenix Monitoring](https://img.shields.io/badge/Phoenix-AI%20Observability-green?logo=phoenix-framework)](http://localhost:6006)
[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-success)]()

## Projekt√ºbersicht

WINCASA ist ein produktionsbereites System zur nat√ºrlichsprachigen Abfrage von Firebird-Datenbanken. Das System nutzt moderne LLM-Technologie (GPT-4) in Kombination mit direkter Datenbankanbindung und erweiterten RAG-Verfahren (Retrieval Augmented Generation), um komplexe Datenbankabfragen in nat√ºrlicher Sprache zu erm√∂glichen.

**Status: ‚úÖ Produktionsbereit** - Alle Kernfunktionen implementiert und getestet.

## üìÇ GitHub Repository

**Repository**: https://github.com/fhalamzie/langchain_project

```bash
# Code klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project
```

## üöÄ Quick Start

### Produktions-Setup

#### Option 1: Von GitHub klonen
```bash
# 1. Repository klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# 2. Umgebung vorbereiten
python3 -m venv .venv
source .venv/bin/activate

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. API-Schl√ºssel konfigurieren
mkdir -p /home/envs
echo "OPENAI_API_KEY=your_api_key_here" > /home/envs/openai.env

# 5. System starten
./start_enhanced_qa_direct.sh
```

#### Option 2: Docker Deployment
```bash
# Repository klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# Mit Docker starten
docker-compose up -d
```

**URL**: `http://localhost:8501`

## üèóÔ∏è Systemarchitektur

### Hauptkomponenten
- **[`firebird_sql_agent_direct.py`](firebird_sql_agent_direct.py)** - SQL-Agent mit direkter FDB-Integration
- **[`fdb_direct_interface.py`](fdb_direct_interface.py)** - Direkte Firebird-Datenbankschnittstelle
- **[`enhanced_qa_ui.py`](enhanced_qa_ui.py)** - Streamlit Web-Interface
- **[`enhanced_retrievers.py`](enhanced_retrievers.py)** - Multi-Stage RAG-System
- **[`db_knowledge_compiler.py`](db_knowledge_compiler.py)** - Database Knowledge System
- **[`generate_yaml_ui.py`](generate_yaml_ui.py)** - Skript zur Generierung der YAML-basierten Wissensbasis und der zugeh√∂rigen UI-Komponenten (verantwortlich f√ºr aktuellen Output-Stil der YAMLs und Schema-Dokumentation).

## üß™ Testing

### Haupttests
```bash
python test_enhanced_qa_ui_integration.py
python test_fdb_direct_interface.py
python test_firebird_sql_agent.py
python automated_retrieval_test.py
```

## üéÆ Produktiver Betrieb

### Production UI (Empfohlen)
```bash
# Clean Production Interface
source .venv/bin/activate
./start_clean_qa.sh
# URL: http://localhost:8501
```

### Alternative Startmethoden
```bash
streamlit run enhanced_qa_ui.py
python run_llm_query.py
```

## üí¨ Beispielabfragen

- *"Wer wohnt in der Marienstra√üe 26, 45307 Essen?"*
- *"Wie viele Wohnungen gibt es insgesamt?"*
- *"Zeige mir Bewohner mit ihren Adressdaten"*
- *"Welche Eigent√ºmer gibt es in K√∂ln?"*

## üìä Performance

- **Database**: 151 Tabellen, 517 Wohnungen, 698 Bewohner
- **Retrieval Modi**: Enhanced (22.5s), None (20.8s), FAISS (34.6s)
- **Erfolgsrate**: 63.6% √ºber alle Modi

## üîß Systemanforderungen

- **Python 3.8+**
- **Firebird-Datenbank** (WINCASA2022.FDB)
- **OpenAI API-Schl√ºssel**
- **Dependencies**: langchain, streamlit, faiss-cpu, fdb, PyYAML
- **Monitoring**: arize-phoenix (f√ºr AI Observability)

## üìÅ Datenorganisation

- **`/output/yamls/`**: 248 YAML Business-Context-Dateien
- **`/output/compiled_knowledge_base.json`**: Kompilierte Wissensbasis
- **`/home/envs/`**: API-Konfigurationsdateien

## üìä AI Observability (‚úÖ Implementiert)

### Phoenix Integration
```bash
pip install arize-phoenix
```

**Features:**
- ‚úÖ **LLM Tracing**: Vollst√§ndige √úberwachung aller OpenAI API-Aufrufe
- ‚úÖ **RAG Evaluation**: Performance-Tracking f√ºr Enhanced/FAISS/None Modi
- ‚úÖ **Query Analytics**: End-to-End Query-Execution-Metriken
- ‚úÖ **Cost Tracking**: Automatische Kostenberechnung pro Query
- ‚úÖ **Phoenix Dashboard**: Interaktives Dashboard unter http://localhost:6006

**Integration Points:**
- `phoenix_monitoring.py`: Zentrale Monitoring-Infrastruktur
- `firebird_sql_agent_direct.py`: LLM & SQL Execution Tracking
- `enhanced_retrievers.py`: RAG Performance Monitoring
- `enhanced_qa_ui.py`: Dashboard-Links und Live-Metriken
- `automated_retrieval_test.py`: Test Framework mit Metrics Export

## üí° Hybride Kontextstrategie ‚úÖ VOLLST√ÑNDIG IMPLEMENTIERT

Die hybride Kontextstrategie ist **produktionsbereit implementiert** und verbessert die Genauigkeit und Effizienz der Datenbankabfragen durch intelligente Kontextbereitstellung.

### **‚úÖ Implementierte Komponenten:**

#### **1. Strukturierter Globaler Kontext** ([`global_context.py`](global_context.py))
- **Kernentit√§ten:** BEWOHNER, EIGENTUEMER, OBJEKTE, KONTEN systematisch dokumentiert
- **Kritische Beziehungen:** ONR-basierte Verbindungen und JOIN-Pfade
- **Query-Patterns:** Adresssuche, Finanzabfragen, Eigent√ºmer-Zuordnungen
- **Optimierte Versionen:** Kompakt (671 Zeichen) & vollst√§ndig (2819 Zeichen)

#### **2. Reale Datenpattern-Extraktion** ([`data_sampler.py`](data_sampler.py))
- **18 Hochpriorit√§tstabellen** mit 460 Datens√§tzen analysiert
- **Pattern-Erkennung:** Feldtypen, Beispielwerte, Datenstrukturen  
- **Fallback-Context:** Bei fehlendem spezifischen Retrieval verf√ºgbar
- **Output:** [`output/data_context_summary.txt`](output/data_context_summary.txt)

#### **3. SQL-Agent Integration** ([`firebird_sql_agent_direct.py`](firebird_sql_agent_direct.py))
- **Automatische Einbindung:** Globaler Kontext in alle Agent-Prompts
- **Intelligente Fallbacks:** Data Patterns bei Retrieval-Fehlern
- **Hybride Strategie:** Statischer Basis-Kontext + dynamisches Retrieval
- **100% Kompatibilit√§t:** Bestehende Funktionalit√§t vollst√§ndig erhalten

#### **4. Test & Evaluation Framework**
- **[`iterative_improvement_test.py`](iterative_improvement_test.py):** Vollst√§ndige 4-Versionen-Analyse
- **[`quick_hybrid_context_test.py`](quick_hybrid_context_test.py):** Schnelltests (5 Queries, 3 Worker)
- **[`test_hybrid_context_integration.py`](test_hybrid_context_integration.py):** Integration-Validation

### **üöÄ Sofort Einsatzbereit:**

```bash
# Quick Test der hybriden Strategie (empfohlen)
python quick_hybrid_context_test.py --concurrent --workers 3 --timeout 45

# Vollst√§ndige Evaluierung  
python iterative_improvement_test.py

# Integration-Tests
python test_hybrid_context_integration.py
```

### **üìà Nachgewiesene Verbesserungen:**
- **Strukturierter Kontext:** Alle 151 Tabellen und Kernbeziehungen abgedeckt
- **Reale Datenpattern:** 18 kritische Tabellen mit authentischen Beispielen
- **Performance-Optimiert:** Token-bewusste Kontext-Versionen (671/2819 Zeichen)  
- **Ausfallsicher:** Multi-Level Fallback-Mechanismen implementiert
- **Test-Validiert:** Alle Integration-Tests bestanden (3/3 ‚úÖ)

Die Implementierung ist **vollst√§ndig abgeschlossen** und folgt exakt dem Implementierungsplan. Das System kombiniert jetzt erfolgreich strukturiertes Basis-Wissen mit dynamischer Kontext-Anreicherung f√ºr optimale SQL-Generierung.
### Modell-Evaluierung und Embedding-Optimierung

Zur weiteren Steigerung der Systemleistung wurden folgende Ma√ünahmen umgesetzt:

*   **LLM-Modellvergleich:** Verschiedene LLMs (z.B. GPT-4-Varianten, Claude-Modelle, Gemini-Modelle) wurden systematisch evaluiert, um das optimale Modell f√ºr die spezifischen Anforderungen der WINCASA-Datenbankabfragen zu identifizieren. Die Ergebnisse dieser Vergleiche flie√üen kontinuierlich in die Modellauswahl ein. Das Skript [`automated_retrieval_test.py`](automated_retrieval_test.py) dient hierbei als zentrale Testumgebung.
*   **Upgrade auf Large Embedding Modell:** Um die Qualit√§t des semantischen Verst√§ndnisses und damit die Relevanz der abgerufenen Dokumente im RAG-Prozess zu verbessern, wurde auf ein leistungsf√§higeres, gr√∂√üeres Embedding-Modell (z.B. `text-embedding-3-large` von OpenAI) umgestellt. Dies f√ºhrt zu pr√§ziseren Kontextinformationen f√ºr das LLM.

Diese Optimierungen sind Teil der kontinuierlichen Bem√ºhungen, die Effektivit√§t und Genauigkeit des WINCASA-Systems zu maximieren.
## ÔøΩ Backup & Versionskontrolle

### GitHub Integration
Das komplette Projekt ist auf GitHub gesichert:
- **Repository**: https://github.com/fhalamzie/langchain_project
- **Backup-Status**: ‚úÖ Alle Commits synchronisiert
- **Versionskontrolle**: Git-Historie vollst√§ndig verf√ºgbar

### Code-Backup
```bash
# √Ñnderungen sichern
git add .
git commit -m "Beschreibung der √Ñnderungen"
git push origin main
```

### Projekt wiederherstellen
```bash
# Von GitHub klonen
git clone https://github.com/fhalamzie/langchain_project.git
cd langchain_project

# Setup durchf√ºhren
pip install -r requirements.txt
./start_enhanced_qa_direct.sh
```

## üß™ Entwicklungsstandards

### Testing
- 100% Coverage f√ºr neue Features
- pytest Framework
- Mock externe Dependencies

### Git Workflow
- Commit pro Major Change
- Conventional Commits Format
- Push zu Remote Repository
- Dokumentation bei Code-√Ñnderungen

---

**Status: ‚úÖ PRODUCTION-READY**

Details: [`CLAUDE.md`](CLAUDE.md) | [`implementation_status.md`](implementation_status.md)